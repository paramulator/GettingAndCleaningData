#### GettingAndCleaningData
This is the repo for the Coursera *Getting and Cleaning Data* class project.  This project involves reading multiple source data files from the wearable computing project by Anguita et al., 2013, and then transforming it into a single tidy dataset. An R script was written to perform all of the data processing activities.  

The wearable computing project involved the collection of data generated by the built-in gyro and accelerometer of a Samsung smartphone.  The smartphone was worn by 30 different human subjects while they performed 6 different activities like walking, standing, sitting, etc.  A vector of 561 "features" was captured at time intervals during the performance of each activity by each subject.  See the [Codebook.md] (https://github.com/paramulator/GettingAndCleaningData/blob/master/CodeBook.md) file contained in this repo for details about the source data and the resulting tidy dataset.  A reference to wearable computing is [here](http://www.insideactivitytracking.com/data-science-activity-tracking-and-the-battle-for-the-worlds-top-sports-brand) and a description of the raw source data for this project is [here](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).  

***

#### Contents of this document
* Instructions for running the R script
* Script details 
    +   Inputs
    +   Outputs
    +   Logic
* Dev environment
* Dependencies
* Some useful links
* Citation

***

#### Instructions for running the R script
1.  Start an R session.
2.  Execute `install.packages("dplyr")` if necessary, and then execute `library(dplyr)`.
3.  The script will be looking for a folder called "UCI Har Dataset" (aka the UCI folder) in the current working directory.  In case the UCI folder already exists (because you've already manually downloaded the data), set your working directory to the parent of this folder.
4.  Execute the script [run_analysis.R] (https://github.com/paramulator/GettingAndCleaningData/blob/master/run_analysis.R).
  + If the UCI folder does not exist, the script will create it, download the source data, and populate the folder with the source data files and other subfolders.
  + An internet connection will be required to download data.
5.  After the script completes locate the file "courseProjectStep5.txt" in the UCI folder.  This is the tidy dataset created from the inputs.
    + If you like you can execute the following to read the file into an R dataframe:
        + `testFrame <- read.table("UCI HAR Dataset//courseProjectStep5.txt", header = TRUE)`
6.  Reference the [CodeBook.md] (https://github.com/paramulator/GettingAndCleaningData/blob/master/CodeBook.md) for details about the contents of the tidy dataset.

***

#### Script details   
The script is in this depo but you can find it [here] (https://github.com/paramulator/GettingAndCleaningData/blob/master/run_analysis.R).

##### Inputs
There are no parameterized inputs to the script.  Instead, all references to external data sources and locally downloaded directories and files are hard-coded. 

The script will automatically download the raw source data from this location as needed:
  https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip

The downloaded data is placed in the UCI folder.  The structure of the folder and relevant input/output files is as follows:

File/Folder | Brief Description
------------|--------------------
**/UCI HAR Dataset** |Root folder for all source data
  features.txt | Reference data file for feature IDs and labels
  activity_labels.txt | Reference data file for activity IDs and labels
  courseProjectStep5.txt | The output tidy dataset
  **/UCI HAR Dataset/test** | Test subset folder
    subject_test.txt | Ordered list of subject IDs in the test set
    y_test.txt | Ordered list of activity IDs in the test set
    X_test.txt | Ordered list of feature vectors in the test set
  **/UCI HAR Dataset/train** | Train subset folder
    subject_train.txt | Ordered list of subject IDs in the training set
    y_train.txt | Ordered list of activity IDs in the training set
    X_train.txt | Ordered list of feature vectors in the training set  

<br>

##### Outputs
A single **WIDE format** tidy dataset is generated as a text file and is placed in the UCI folder.  The text file is called "courseProjectStep5.txt" and will have a column header row, 180 data rows, and 66 columns.

Each data row represents an observation on each combination of 30 human subjects and 6 activities.  The first two columns are the subject ID and activity label.  Each of the 64 feature columns represents the mean value of a feature for the subject/activity combo taken across a number of time intervals.  See the [CodeBook.md] (https://github.com/paramulator/GettingAndCleaningData/blob/master/CodeBook.md) for details.  

<br>  

##### Logic overview
1. Establish pointers to the external data and each of the required files in the UCI folder.  If the folder does not exist, download the external data as a zip file and unzip it into the UCI folder.  If a text file called "courseProjectStep5.txt" exists in the UCI folder, remove it.
2. Read the reference data files for features and activites.  Features were given descriptive labels in the raw data and are not suitable as valid R column names.  They are cleaned up to produce suitable tidy column names.   
3. Process the 3 files in the test folder by reading them into individual data frames, concatenating them column-wise, and subsetting the columns down to just those specific features that represent means and standard deviations of the raw time interval data.  
    + When reading the feature vectors test file we'll use the feature reference dataframe to generate the column names for the elements of the feature vectors. 
    + We'll match the activity IDs in the activity test file with the IDs in the activity reference dataframe to pick up the activity labels.  
    + The result will be a tidy dataset with one variable per column and one observation per row.  
    + Do the same for the 3 files in the train folder.    
4. Concatenate the test and train tidy datasets row-wise into a single dataset.
5. Group the data by subject ID and activity label, and compute the mean value of each feature variable. 
6. Write the summarized data to "courseProjectStep5.txt" file in the UCI folder.  This is the output tidy dataset. 
7. Validation: the text file can be read by executing:
    + `testFrame <- read.table("UCI HAR Dataset//courseProjectStep5.txt", header = TRUE)` 

***

#### Dev environment
The state of the R environment during script development and testing:

 setting | value
 --------|--------------------------------
 version | R version 3.2.1 (2015-06-18)
 system  | x86_64, mingw32             
 ui      | RStudio (0.99.484)          
 language | (EN)                        
 collate  | English_United States.1252  
 tz       | America/Chicago             
 date     | 2015-10-21                  

***

#### Dependencies 
Packages that were loaded to enable tidy data manipulations:

 package |    * version date|       source 
 --------|------------------|------------------
 dplyr |      * 0.4.3 |   2015-09-01 CRAN (R 3.2.2)

***

#### Useful links regarding tidy data and variable naming references
* Tidy data course notes: http://jtleek.github.io/modules/03_GettingData/01_03_componentsOfTidyData
* How to share data with a statistician: https://github.com/jtleek/datasharing
* The Elements of Data Analytic Style: https://leanpub.com/datastyle
* Hadley Wickham's paper on tidy data: http://vita.had.co.nz/papers/tidy-data.pdf
* 18 months of CTA advice for this class: https://thoughtfulbloke.wordpress.com/2015/08/31/hello-world

***

#### Citation
Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012
